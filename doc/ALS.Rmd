---
title: "ALS"
author: "Ziyang Zhang, Huizhe Zhu"
date: "4/16/2020"
output: html_document
---

Input: f, lambda, max.iter, data, train=data_train
Output: generate different files for q (item vector) and r (estimated rating), written as A3_q_f(n).csv and A3_r_f(n).csv   (Note:n is the number of factors)


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Step 1 Load Data and Train-test Split
```{r}
# rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
train_set <- data[train_idx, ]
test_set <- data[test_idx, ]
write.csv(train_set,file="train_set.csv",row.names = F)
write.csv(test_set, file = "test_set.csv", row.names = F)
data_train <- read.csv("train_set.csv")
data_test <- read.csv("test_set.csv")
```

```{r}
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/ALS.R")
```

```{r}
#Define a function to calculate RMSE
RMSE <- function(rating, est_rating){
  sqr_err <- function(obs){
    sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
    return(sqr_error)
  }
  return(sqrt(mean(apply(rating, 1, sqr_err))))  
}

ALS <- function(f = 10, lambda = 5, max.iter=20, data, train=data_train, test=data_test) {
  
  # Initialize Movie Matrix and User Matrix
  Movie <- matrix(runif(f*I, -1, 1), ncol = I)
  colnames(Movie) <- levels(as.factor(data$movieId))
  movie.average <- data %>% 
    group_by(movieId) %>% 
    summarize(ave=mean(rating))
  Movie[1,] <- movie.average$ave
  
  
  User <- matrix(runif(f*U, -1, 1), ncol = U) 
  colnames(User) <- levels(as.factor(data$userId))
  
  
  movie.id <- sort(unique(data$movieId))
  train_RMSE <- c()
  test_RMSE <- c()
  
  for (l in 1:max.iter){
  
  # Step2: Fix M, Solve U
  for (u in 1:U) {
    
    User[,u] <- solve (Movie[,as.character(train[train$userId==u,]$movieId)] %*%
      t(Movie[,as.character(train[train$userId==u,]$movieId)]) + lambda * diag(f)) %*%
      Movie[,as.character(train[train$userId==u,]$movieId)] %*% train[train$userId==u,]$rating}
    
    
  # Step3: Fix U, Solve M  
  for (i in 1:I) {
    Movie[,i] <- solve (User[,train[train$movieId==movie.id[i],]$userId] %*% 
      t(User[,train[train$movieId==movie.id[i],]$userId]) + lambda * diag(f)) %*%
      User[,train[train$movieId==movie.id[i],]$userId] %*% train[train$movieId==movie.id[i],]$rating
    
  }
    
    
    # Summerize
    cat("iter:", l, "\t")
    est_rating <- t(User) %*% Movie 
    colnames(est_rating) <- levels(as.factor(data$movieId))
    
    train_RMSE_cur <- RMSE(train, est_rating)
    cat("training RMSE:", train_RMSE_cur, "\t")
    train_RMSE <- c(train_RMSE, train_RMSE_cur)
    
    test_RMSE_cur <- RMSE(test, est_rating)
    cat("test RMSE:",test_RMSE_cur, "\n")
    test_RMSE <- c(test_RMSE, test_RMSE_cur)
    
  } 
  ratings<-t(as.matrix(Movie))%*%as.matrix(User)
  return(list(p = User, q = Movie, r= ratings, train_RMSE = train_RMSE, test_RMSE = test_RMSE))
}
```

In order to apply the ALS algorithm, we write a function that do the minimization of the loss function. 

We take the derivative of the loss function and set it to zero. Then we alternatively fix p or q to solve for the other.  Since we are working with matrix, so the first step is to initilize a matrix for movies and users. Then we solve of p and q alternatively by fixing the other and set the derivative of loss function to zero. Then we get the RMSE by tuning different lambda and factors.

f = 10, l = 5
```{r}
#the r matrix and q matrix for factor of 10, lambda of 5 and RMSE
als1= ALS(f = 10, lambda = 5, max.iter=10, data, train=data_train, test=data_test)
mat1= als1$q
mat2= als1$r
write.csv(mat1, file = "A3_q_f10.csv")
write.csv(mat2, file = "A3_r_f10.csv")

```


Calculate RMSE and Visualize the result： f = 10 
```{r}
RMSE_f10 <- data.frame(epochs = seq(10, 100, 10), Training_RMSE = als1$train_RMSE, Test_RMSE = als1$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)

RMSE_f10 %>% ggplot(aes(x = epochs, y = RMSE,col = train_or_test)) + 
  geom_point() + 
  scale_x_discrete(limits = seq(10, 100, 10)) + 
  xlim(c(0, 100)) + 
  ggtitle("RMSE with f = 10") 
```



f = 50, l = 5
```{r}
#the r matrix and q matrix for factor of 50, lambda of 5 and RMSE
als2= ALS(f = 50, lambda = 5, max.iter=10, data, train=data_train, test=data_test)
mat3= als2$q
mat4=als2$r
write.csv(mat3, file = "A3_q_f50.csv")
write.csv(mat4, file =  "A3_r_f50.csv")
```

Calculate RMSE and Visualize the result： f = 50 
```{r}
RMSE_f50 <- data.frame(epochs = seq(10, 100, 10), Training_RMSE = als2$train_RMSE, Test_RMSE = als2$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)

RMSE_f50 %>% ggplot(aes(x = epochs, y = RMSE,col = train_or_test)) + 
  geom_point() + 
  scale_x_discrete(limits = seq(10, 100, 10)) + 
  xlim(c(0, 100)) + 
  ggtitle("RMSE with f = 50") 
```


f = 100, l = 5
```{r}
#the r matrix and q matrix for factor of 100, lambda of 5 and RMSE
als3= ALS(f = 100, lambda = 5, max.iter=10, data, train=data_train, test=data_test)
mat5= als3$q
mat6= als3$r
write.csv(mat5, file =  "A3_q_f100.csv")
write.csv(mat6, file =  "A3_r_f100.csv")
```
write.csv(mat1, file = "A3_q_f10.csv")
write.csv(mat2, file = "A3_r_f10.csv")
write.csv(mat3, file = "A3_q_f50.csv")
write.csv(mat4, file =  "A3_r_f50.csv")

```{r}
save(mat1, file = "A3_q_f10.RData")
save(mat2, file = "A3_r_f10.RData")

```

Calculate RMSE and Visualize the result： f = 100
```{r}
RMSE_f100 <- data.frame(epochs = seq(10, 100, 10), Training_RMSE = als3$train_RMSE, Test_RMSE = als3$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)

RMSE_f100 %>% ggplot(aes(x = epochs, y = RMSE,col = train_or_test)) + 
  geom_point() + 
  scale_x_discrete(limits = seq(10, 100, 10)) + 
  xlim(c(0, 100)) + 
  ggtitle("RMSE with f = 100") 
```



plot the graph for als  <- c (als1, als2, als3)
```{r}
als <- c(als1,als2,als3)
#plot out the result
library(ggplot2)
#result= ALS(f = 100, lambda = 5, max.iter=10, data, train=data_train, test=data_test)
RMSE1 <- data.frame(epochs = seq(10, 100, 10), Training_MSE =als$train_RMSE, Test_MSE = als$test_RMSE) %>% 
  gather(key = train_or_test, value = RMSE, -epochs)

RMSE1 %>% 
  ggplot(aes(x = epochs, y = RMSE,col = train_or_test)) + geom_point() + scale_x_discrete(limits = seq(10, 100, 10)) + xlim(c(0, 100))
```

From above, we can tell that the MSE for Test data and Training data decreases in overall. For the RMSE of training data is much more steep. The overall decrease of the RMSE does show good result for ALS. 

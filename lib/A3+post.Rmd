---
title: "P3"
author: "Ziyang Zhang"
date: "4/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
#installed.packages("remotes")
remotes::install_github("TimothyKBook/krr")
#installed.packages("krr")
library(krr)
library(dplyr)
library(caret)
```

# A3 with 10 factors

```{r}
#read output and data
train_set<-read.csv("../data/train_set.csv")
test_set<-read.csv("../data/test_set.csv")
q<-read.csv("../output/A3_q_dim10.csv",header= FALSE)
# rating.a3<-read.csv("../output/A3_r_dim10.csv",header=FALSE)
rating.a3 <- read.csv("../output/A3_r_dim10.csv",header=FALSE)
```

## Prepare for kernel ridge regression input

We need to transform the results from ALS to the form that we can put into kernel ridge regression. 

First, we should split rating data for 610 users since we should do krr for different users. Second, each column of q matrix we have from ALS represents a movie. We should to etract certain column of q matrix corresponding to the movie(movieid) users rating and then combine them to build 610 different transformed new q matrices. Finally, we need to normalize each row.


```{r}
train_split <- split(train_set,train_set$userId)
n <- length(train_split)
movie <- as.vector(unlist(c(q[1,])))
### Function to normalize each row
norm.row <- function(m){
  return(m/sqrt(sum(m^2)))
}
q <- as.matrix(q[-1,])
new_q_split <- list()
for (k in 1:n){
  new <- c()
for (i in 1:dim(train_split[[k]])[1]){
  new<-cbind(new,q[,which(movie == train_split[[k]]$movieId[i])])}
  new_q_split[[k]]<-new
}
q_t <- apply(q,2,norm.row)
q_t[which(is.na(q_t))] <- 0
x_split<-list()
for (k in 1: n){
  x_split[[k]]<-apply(new_q_split[[k]],2,norm.row)
}
data_split<-list()
for (k in 1:n){
  data_split[[k]] <- cbind(train_split[[k]]$rating,t(x_split[[k]]))
  }
#save(data_split,file = "../output/data_split1.RData")
```

## Tuning parameter for kernel ridge regression

We set the Gaussian kernel: $K(x_i^{T},x_j^{T}) = exp(2(x_i^{T}x_j - 1))$ as the paper said and we'll use k-folds cross validation to get the value of parameter $\lambda$

```{r}
source("../lib/cv.krr.R")
#find a best lambda
rmse_tune <- data.frame(lambdas=c(0.7,0.8,0.9),rmse=rep(0,length(lambdas)))
for (i in 1:length(lambdas)){
  m <- lapply(data_split, cv.krr, 5, lambdas[i])
  rmse_tune[i,2] <-  sum(unlist(m))
}
rmse_tune
```

## Train kernel ridge regression and get prediction
From the result above, we could see that 0.7 is the best value for $\lambda$ with the minimized RSME. As a result, we will use 0.7 to train 610 KRR for 610 users.

```{r}
n <- length(data_split)
### Each user has his KRR model. 
train_model <- vector(mode="list",length=n)
for(i in 1:n){
   train_model[[i]] <- krr(x = data_split[[i]][,-1],
                           y = data_split[[i]][,1],
                           lambda = 0.7)
}
pred.rating<-matrix(0,nrow=length(data_split),ncol=dim(q)[2])

for (i in 1:n){
  pred.rating[i,] <- predict(train_model[[i]],t(q_t))
}
rating.a3 <- t(rating.a3)
rating.a3 <- rating.a3[-1,]
colnames(rating.a3) <- c(as.character(movie))
rownames(rating.a3) <- c(1:610)
colnames(pred.rating)<-c(as.character(movie))
rownames(pred.rating)<-c(1:610)
mse<-function(data,
              test){
  movie.id <- data$movieId
  user.id <- data$userId
  pred <- as.numeric(t(test[match(c(as.character(user.id)),rownames(test)),
                            match(c(as.character(movie.id)),colnames(test))]))
  return(mean((data$rating-pred)^2))
}
```

## Compute weighted average of algrithms predicition and krr prediction

We combined the predictions together and see if using weighted average will help further minimize RMSE. And we used cross validation to get the best weight.  

For factor numbers of 10, we find the best weight is 0.7, which means krr has better prediction than ALS for nearly 70% ratings.
But for 50 and 100 factors, the best weight is 1 which means krr is totally better than AlS. Maybe that's the point we should fo post processing after the algorithms.

```{r}
weights <- seq(0,1,0.1)
n <- length(weights)
rmse.train <- data.frame(weights=weights,rmse=rep(0,n))
rating.weighted<-list()
# mse.n <- function(rating = rating.a3,
#                   weight = weights,
#                   pred = pred.rating)
  
for (i in 1:n){
  rating.weighted[[i]]<- rating.a3*(1-weights[i]) + pred.rating*weights[i]
    # rating.weighted[[1]]<- rating.a3*(1-weights[1]) + pred.rating*weights[1]

  rating.weighted[[i]]<-as.matrix(rating.weighted[[i]])
    # rating.weighted[[1]]<-as.matrix(rating.weighted[[1]])

  mse1<-mse(train_set[1:10000,],
             rating.weighted[[1]])
  mse2<-mse(train_set[10001:20000,],
             rating.weighted[[i]])
  mse3<-mse(train_set[20001:30000,],
             rating.weighted[[i]])
  mse4<-mse(train_set[30001:40000,],
             rating.weighted[[i]])
  mse5<-mse(train_set[40001:50000,],
             rating.weighted[[i]])
  mse6<-mse(train_set[50001:60000,],
             rating.weighted[[i]])
  mse7<-mse(train_set[60001:70000,],
             rating.weighted[[i]])
  mse8<-mse(train_set[70001:80000,],
             rating.weighted[[i]])
  mse9<-mse(train_set[80001:dim(train_set)[1],],
            rating.weighted[[i]])
  rmse.train[i,2]<-sqrt(((mse1+mse2+mse3+mse4+mse5+mse6+mse7+mse8)*10000+(dim(train_set)[1]-80000)*mse9)/dim(train_set)[1])
}
rmse.train
```

## Evaluation

```{r}
#get test rmse
best_weight <- match(min(rmse.train$rmse), rmse.train$rmse)
dim(test_set)[1]
mse11<-mse(test_set[1:10000,],rating.weighted[[best_weight]])
  mse21<-mse(test_set[10001:20000,],rating.weighted[[best_weight]])
  mse32<-mse(test_set[20001:dim(test_set)[1],],rating.weighted[[best_weight]])
  rmse.test<-sqrt(((mse11+mse21)*10000+(dim(test_set)[1]-20000)*mse32)/dim(test_set)[1])
  rmse.test
```

```{r}
q <- read.csv("../output/A3_q_dim50.csv",header= FALSE)
rating.a3<-read.csv("../output/A3_r_dim50.csv",header=FALSE)
rating.a3.1 <- read.csv("../data/A3_r_f10.csv")
movie <- as.vector(unlist(c(q[1,])))
n <- length(train_split)
q <- as.matrix(q[-1,])
new_q_split <- list()
for (k in 1:n){
  new <- c()
for (i in 1:dim(train_split[[k]])[1]){
  new<-cbind(new,q[,which(movie == train_split[[k]]$movieId[i])])}
  new_q_split[[k]]<-new
}
q_t <- apply(q,2,norm.row)
q_t[which(is.na(q_t))] <- 0
x_split<-list()
for (k in 1: n){
  x_split[[k]]<-apply(new_q_split[[k]],2,norm.row)
}
data_split<-list()
for (k in 1:n){
  data_split[[k]] <- cbind(train_split[[k]]$rating,t(x_split[[k]]))
  }
rmse_tune <- data.frame(lambdas = c(0.55,0.6,0.65),rmse=rep(0,length(lambdas)))
for (i in 1:length(lambdas)){
  m <- lapply(data_split, 
              cv.krr, 
              5, 
              lambdas[i])
  rmse_tune[i,2] <-  sum(unlist(m))
}
rmse_tune
# The best lambda is 0.55. 
n <- length(data_split)
### Each user has his KRR model. 
train_model <- vector(mode="list",length=n)
for(i in 1:n){
   train_model[[i]] <- krr(x = data_split[[i]][,-1],
                           y = data_split[[i]][,1],
                           lambda = 0.7)
}
pred.rating<-matrix(0,nrow=length(data_split),ncol=dim(q)[2])
for (i in 1:n){
  pred.rating[i,] <- predict(train_model[[i]],t(q_t))
}
rating.a3<-rating.a3[-1,]
colnames(rating.a3)<-c(as.character(movie))
rownames(rating.a3)<-c(1:610)
colnames(pred.rating)<-c(as.character(movie))
rownames(pred.rating)<-c(1:610)

weights <- seq(0,1,0.1)
n <- length(weights)
rmse_train <- data.frame(weights=weights,rmse=rep(0,n))
rating.weighted<-list()

for (i in 1:n){
  rating.weighted[[i]]<- rating.a3*(1-weights[i]) + pred.rating*weights[i]
  rating.weighted[[i]]<-as.matrix(rating.weighted[[i]])
}
  
  
  
for(i in 1:n){
  mse1<-mse(train_set[1:20000,],rating.weighted[[i]])
  mse2<-mse(train_set[20001:40000,],rating.weighted[[i]])
  mse3<-mse(train_set[40001:60000,],rating.weighted[[i]])
  mse4<-mse(train_set[60001:80000,],rating.weighted[[i]])
  # mse5<-mse(train_set[40001:50000,],rating.weighted[[i]])
  # mse6<-mse(train_set[50001:60000,],rating.weighted[[i]])
  # mse7<-mse(train_set[60001:70000,],rating.weighted[[i]])
  # mse8<-mse(train_set[70001:80000,],rating.weighted[[i]])
  mse5<-mse(train_set[80001:dim(train_set)[1],],rating.weighted[[i]])
  rmse.train[i,2]<-sqrt(((mse1+mse2+mse3+mse4+mse5+mse6+mse7+mse8)*10000+(dim(train_set)[1]-80000)*mse9)/dim(train_set)[1])
}
rmse.train
```

```{r}
#get test rmse
best_weight <- match(min(rmse.train$rmse), rmse.train$rmse)
  mse11<-mse(test_set[1:10000,],rating.weighted[[best_weight]])
  mse21<-mse(test_set[10001:20000,],rating.weighted[[best_weight]])
  mse32<-mse(test_set[20001:dim(test_set)[1],],rating.weighted[[best_weight]])
  rmse_test<-sqrt(((mse11+mse21)*10000+(dim(test_set)[1]-20000)*mse32)/dim(test_set)[1])
  rmse_test
```

## A3 with 100 factors

```{r}
q<-read.csv("../output/A3_q_dim100.csv",header= FALSE)
rating.a3<-read.csv("../output/A3_r_dim100.csv",header=FALSE)
movie <- as.vector(unlist(c(q[1,])))
q <- as.matrix(q[-1,])
n <- length(train_split)
new_q_split <- list()
for (k in 1:n){
  new <- c()
for (i in 1:dim(train_split[[k]])[1]){
  new<-cbind(new,q[,which(movie == train_split[[k]]$movieId[i])])}
  new_q_split[[k]]<-new
}
q_t <- apply(q,2,norm.row)
q_t[which(is.na(q_t))] <- 0
x_split<-list()
for (k in 1: n){
  x_split[[k]]<-apply(new_q_split[[k]],2,norm.row)
}
data_split<-list()
for (k in 1:n){
  data_split[[k]] <- cbind(train_split[[k]]$rating,t(x_split[[k]]))
  }
rmse_tune <- data.frame(lambdas = c(0.5,0.6,0.7),rmse=rep(0,length(lambdas)))
for (i in 1:length(lambdas)){
  m <- lapply(data_split, 
              cv.krr, 
              5, 
              lambdas[i])
  rmse_tune[i,2] <-  sum(unlist(m))
}
# The best lambda is 0.5. 
n <- length(data_split)
### Each user has his KRR model. 
train_model <- vector(mode="list",length=n)
for(i in 1:n){
   train_model[[i]] <- krr(x = data_split[[i]][,-1],
                           y = data_split[[i]][,1],
                           lambda = 0.5)
}
pred.rating<-matrix(0,nrow=length(data_split),ncol=dim(q)[2])
for (i in 1:n){
  pred.rating[i,] <- predict(train_model[[i]],t(q_t))
}
rating.a3<-rating.a3[-1,]
colnames(rating.a3)<-c(as.character(movie))
rownames(rating.a3)<-c(1:610)
colnames(pred.rating)<-c(as.character(movie))
rownames(pred.rating)<-c(1:610)

weights <- seq(0,1,0.1)
n <- length(weights)
rmse_train <- data.frame(weights=weights,rmse=rep(0,n))
rating.weighted<-list()
for (i in 1:n){
  rating.weighted[[i]]<- rating.a3*(1-weights[i]) + pred.rating*weights[i]
  rating.weighted[[i]]<-as.matrix(rating.weighted[[i]])
  mse1<-mse(train_set[1:10000,],rating.weighted[[i]])
  mse2<-mse(train_set[10001:20000,],rating.weighted[[i]])
  mse3<-mse(train_set[20001:30000,],rating.weighted[[i]])
  mse4<-mse(train_set[30001:40000,],rating.weighted[[i]])
  mse5<-mse(train_set[40001:50000,],rating.weighted[[i]])
  mse6<-mse(train_set[50001:60000,],rating.weighted[[i]])
  mse7<-mse(train_set[60001:70000,],rating.weighted[[i]])
  mse8<-mse(train_set[70001:80000,],rating.weighted[[i]])
  mse9<-mse(train_set[80001:dim(train_set)[1],],rating.weighted[[i]])
  rmse.train[i,2]<-sqrt(((mse1+mse2+mse3+mse4+mse5+mse6+mse7+mse8)*10000+(dim(train_set)[1]-80000)*mse9)/dim(train_set)[1])
}
rmse.train

##### Evaluation
#get test rmse
best_weight <- match(min(rmse.train$rmse), rmse.train$rmse)
dim(test_set)[1]
mse11<-mse(test_set[1:10000,],rating.weighted[[best_weight]])
  mse21<-mse(test_set[10001:20000,],rating.weighted[[best_weight]])
  mse32<-mse(test_set[20001:dim(test_set)[1],],rating.weighted[[best_weight]])
  rmse.test<-sqrt(((mse11+mse21)*10000+(dim(test_set)[1]-20000)*mse32)/dim(test_set)[1])
  rmse.test
# [1] 20167
# [1] 1.227545 
```

